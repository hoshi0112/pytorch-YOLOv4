{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoshi0112/pytorch-YOLOv4/blob/master/classification_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 掛載雲端硬碟"
      ],
      "metadata": {
        "id": "mxYMqYCZmTm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybD9ojSAAuPI",
        "outputId": "15219d01-bbd6-4773-d8c3-beaaea1654cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -uq \"/content/drive/MyDrive/HW2_dataset.zip\" -d \"/content/sample_data/\""
      ],
      "metadata": {
        "id": "vG5cGhL4qCzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3810a678-d2cc-4380-b426-7b9fb0318a4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/HW2_dataset.zip, /content/drive/MyDrive/HW2_dataset.zip.zip or /content/drive/MyDrive/HW2_dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 載入需要的 Module"
      ],
      "metadata": {
        "id": "ItPFQrbvA8bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch 相關\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import models\n",
        "# 其他\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from copy import copy\n",
        "import os"
      ],
      "metadata": {
        "id": "q5RKJsNVA6_3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('GPU state:', device)"
      ],
      "metadata": {
        "id": "gi8hFZEZGXD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130153d6-da9e-4b53-c216-b0378e9c2178"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU state: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 設置超參數"
      ],
      "metadata": {
        "id": "9FYgZegHI8Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "batch_size = 512\n",
        "epochs = 100\n",
        "model_path = '/content/sample_data/model.pth'\n",
        "train_path = '/content/sample_data/HW2_dataset/training'\n",
        "test_path = '/content/sample_data/HW2_dataset/testing'"
      ],
      "metadata": {
        "id": "79tbkTbxJCFo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 數據預處理"
      ],
      "metadata": {
        "id": "3MXk8kKRJQMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "wN-8fiyxJYhG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 載入 Dataset"
      ],
      "metadata": {
        "id": "HnedtuA7Jgsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar10(Dataset):\n",
        "  def __init__(self, root_dir, transform=None):\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "    self.classes = os.listdir(root_dir)\n",
        "    self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "    self.images = self.load_images()\n",
        "\n",
        "  def get_classes(self):\n",
        "    return self.classes\n",
        "\n",
        "  def load_images(self):\n",
        "      images = []\n",
        "      for cls_name in self.classes:\n",
        "          cls_dir = os.path.join(self.root_dir, cls_name)\n",
        "          # 確保 cls_dir 是一個目錄\n",
        "          if os.path.isdir(cls_dir):\n",
        "              for img_name in os.listdir(cls_dir):\n",
        "                  img_path = os.path.join(cls_dir, img_name)\n",
        "                  images.append((img_path, self.class_to_idx[cls_name]))\n",
        "          else:\n",
        "              cls_dir = '/content/sample_data/HW2_dataset/testing'\n",
        "              for img_name in os.listdir(cls_dir):\n",
        "                  img_path = os.path.join(cls_dir, img_name)\n",
        "                  images.append((img_path, self.class_to_idx[cls_name]))\n",
        "      return images\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path, label = self.images[idx]\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    if self.transform:\n",
        "        img = self.transform(img)\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "3t56xSM_JuHJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Cifar10(train_path,train_transform)\n",
        "test_dataset = Cifar10(test_path,test_transform)\n"
      ],
      "metadata": {
        "id": "m8MypmsZs-Fl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c82d84b8-682f-4618-a301-06b9724d1cd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/HW2_dataset/training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3773677735.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2545943518.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, transform)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/HW2_dataset/training'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_dataset.get_classes()\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "yYjonvhnuvDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 載入 Dataloader"
      ],
      "metadata": {
        "id": "7T9isYs1tbdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=True,num_workers=2)"
      ],
      "metadata": {
        "id": "loIOSwk7aUCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = iter(train_loader)\n",
        "\n",
        "inputs, labels = next(data_iterator)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    img = inputs[i]\n",
        "    #  (channels, height, width) in PyTorch => (height, width, channels)\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    title = classes[labels[i]]\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "plt.suptitle(f'Trainging Data', y=0.93)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9u19dQFvtsDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = iter(test_loader)\n",
        "\n",
        "inputs, labels = next(data_iterator)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    img = inputs[i]\n",
        "    #  (channels, height, width) in PyTorch => (height, width, channels)\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "\n",
        "    plt.axis('off')\n",
        "plt.suptitle(f'Trainging Data', y=0.93)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84s4ip6Ku_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 定義模型"
      ],
      "metadata": {
        "id": "8g4wZ9DYwJPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(weights='DEFAULT')\n",
        "print(model)"
      ],
      "metadata": {
        "id": "xAXnPt13viea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_fcin = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_fcin, len(classes))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "GVWyT9tQw5u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 定義 Cost function"
      ],
      "metadata": {
        "id": "ZelcXPO0xxBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "Ws_XsALYxe9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 開始訓練"
      ],
      "metadata": {
        "id": "Y-Bjtme7yq8m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIeX_dxqC8X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# best model accurancy\n",
        "best_acc = 0.0\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  train_epoch_loss = 0.0\n",
        "\n",
        "  train_class_correct = list(0. for i in range(len(classes)))\n",
        "  train_class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Compute Loss & Update Weight\n",
        "    batch_loss = loss(outputs, labels)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_epoch_loss += batch_loss.item()\n",
        "\n",
        "    # Compute train_class_correct of each batch\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    batch_correct = (predicted == labels)\n",
        "    for j in range(len(labels)):\n",
        "      label = labels[j]\n",
        "      train_class_correct[label] += batch_correct[j].item()\n",
        "      train_class_total[label] += 1\n",
        "\n",
        "  # Compute Loss & Acc\n",
        "  train_epoch_loss = train_epoch_loss / len(train_loader)\n",
        "  train_epoch_accurncy = sum(train_class_correct) / sum(train_class_total) * 100\n",
        "\n",
        "  train_loss.append(train_epoch_loss)\n",
        "  train_acc.append(train_epoch_accurncy)\n",
        "\n",
        "  print('[Epoch:%2d]' % (epoch + 1))\n",
        "  print('Train Accuracy of All : %.3f %%' % (train_epoch_accurncy))\n",
        "  print('Train Loss of All : %.3f ' % (train_epoch_loss))\n",
        "  print(\"----------------------------------------\")\n",
        "\n",
        "  # Validation class correct & class total\n",
        "  val_loss = 0.0\n",
        "  val_class_correct = list(0. for i in range(len(classes)))\n",
        "  val_class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "  # Validation every epoch\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      images, labels = data\n",
        "      images, labels = images.to('cpu'), labels.to('cpu')\n",
        "      outputs = model(images)\n",
        "\n",
        "      # 1. Compute val_batch_loss\n",
        "      batch_loss = loss(outputs, labels)\n",
        "      val_loss += batch_loss.item()\n",
        "\n",
        "      # 2. Compute val_class_correct of each batch\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      batch_correct = (predicted == labels)\n",
        "      for j in range(batch_size):\n",
        "        label = labels[j]\n",
        "        val_class_correct[label] += batch_correct[j].item()\n",
        "        val_class_total[label] += 1\n",
        "  # print each class accurancy of Validation\n",
        "  for i in range(len()):\n",
        "    label = classes[i]\n",
        "    print('Accuracy of %5s : %2d %%' % (label, 100 * val_class_correct[i] / val_class_total[i]))\n",
        "  # Compute Loss & Acc of Validation\n",
        "  val_accurncy = sum(val_class_correct) / sum(val_class_total) * 100\n",
        "  val_loss = val_loss / len(test_loader)\n",
        "\n",
        "  test_loss.append(val_loss)\n",
        "  test_acc.append(val_accurncy)\n",
        "\n",
        "  print('Validation Accuracy of All : %.3f %%' % (val_accurncy))\n",
        "  print('Validation Loss of All : %.3f ' % (val_loss))\n",
        "  print(\"----------------------------------------\")\n",
        "\n",
        "  # Save best model\n",
        "  if val_accurncy > best_acc:\n",
        "    best_acc = val_accurncy\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "      n_correct = 0\n",
        "      n_samples = 0\n",
        "      n_class_correct = [0 for i in range(len(classes))]\n",
        "      n_class_samples = [0 for i in range(len(classes))]\n",
        "      for images, labels in test_loader:\n",
        "          images, labels = data\n",
        "          images, labels = images.to('cpu'), labels.to('cpu')\n",
        "\n",
        "          outputs = model(images)\n",
        "          # max returns (value, index)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          n_samples += labels.size(0)\n",
        "          n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "          print(labels)\n",
        "          for j in range(batch_size):\n",
        "              print(j)\n",
        "              print(labels[0])\n",
        "              print(labels[1])\n",
        "              print(labels[2])\n",
        "              print(labels[3])\n",
        "              label = labels[j-1]\n",
        "              pred = predicted[j-1]\n",
        "              if (label == pred):\n",
        "                  n_class_correct[label] += 1\n",
        "              n_class_samples[label] += 1\n",
        "\n",
        "      acc = 100.0 * n_correct / n_samples\n",
        "      print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "      for i in range(len(classes)):\n",
        "          acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "          print(f'Accuracy of {i}: {acc} %')"
      ],
      "metadata": {
        "id": "79Bm9zlSypm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('Homework2.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Image', 'Label'])\n",
        "    for labels, pred in enumerate(test_predictions):\n",
        "        writer.writerow([labels[], pred])"
      ],
      "metadata": {
        "id": "dvhiznF05GNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nA7SN2Ab6CZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(list(i+1 for i in range(epochs)),train_loss, 'b')\n",
        "plt.plot(list(i+1 for i in range(epochs)),test_loss, 'r')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oCRTGs-v2Fr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Accurancy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(list(i+1 for i in range(epochs)),train_acc, 'b')\n",
        "plt.plot(list(i+1 for i in range(epochs)),test_acc, 'r')\n",
        "plt.legend(['train','test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N4XMplHL7Ws9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}